---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

https://bookdown.org/rdpeng/RProgDA/mapping.html
```{r}
library(ggplot2)
library(tidyverse)
library(maps)
library(sf)
```

```{r}
frackdir='/Users/harry/OneDrive - University of Pittsburgh/Fracking Study Data'
setwd(frackdir)
subdir = "DEP BCW Wastewater Facilities"
depdir = paste(frackdir,"/",subdir,sep="")
print(depdir)
setwd(depdir)
geo = read.csv("./Geocodes/ourWastewaterFULL.csv")
```

```{r}
head(geo)
```


what about the missing values? What's up?
```{r}
states = st_as_sf(map("state",plot=FALSE,fill=TRUE))
pa <-map_data('county',region='pennsylvania')
pa_counties<-st_as_sf(map('county',region='pennsylvania',plot=FALSE,fill=TRUE))
head(states)
```
https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html

```{r}
ggplot(data=pa_counties)+
  geom_sf()+
  #geom_point(data=geo,aes(x=long,y=lat))+
  theme_void()
```
```{r}
pa_lat_min=39
pa_lat_max=43
pa_long_min=-81
pa_long_max=-73
new_geo <- geo%>% filter(lat >= pa_lat_min) %>% filter(lat <=pa_lat_max) %>% filter(long >=pa_long_min) %>% filter(long <=pa_long_max)
nrow(new_geo)
```

```{r}
ggplot(data=pa_counties)+
  geom_sf()+
  geom_point(data=new_geo,aes(x=long,y=lat))+
  theme_void()
```
consider looking at https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html to see how to show limited surrounding areas.
```{r}
pa_geo <- new_geo %>% filter(grepl(", PA",.$addr))
ggplot(data=pa_counties)+
  geom_sf()+
  geom_point(data=pa_geo,aes(x=long,y=lat))+
  theme_void()
```
```{r}
library(rvest)
library(rjson)
# https://towardsdatascience.com/geocoding-tableau-and-r-integration-c5b32dc0eda6
geocode <- function(name, address, city, state, zipcode){
  # NOMINATIM SEARCH API URL
  src_url <- "https://nominatim.openstreetmap.org/search?q="
  
  # CREATE A FULL ADDRESS
  # put in + instead of space
  address = str_replace_all(string = address, pattern = "\\s", 
                         replacement = "+")
  addr <- paste(address, city, state, zipcode, sep = "%2C")
  
  # CREATE A SEARCH URL BASED ON NOMINATIM API TO RETURN GEOJSON
  requests <- paste0(src_url, addr, "&format=geojson")
  
  print(requests)
    
    # QUERY THE API TRANSFORM RESPONSE FROM JSON TO R LIST
    response <- read_html(requests) %>%
      html_node("p") %>%
      html_text() %>%
      fromJSON()
    
    
    # FROM THE RESPONSE EXTRACT LATITUDE AND LONGITUDE COORDINATES
    lon <- response$features[[1]]$geometry$coordinates[1]
    lat <- response$feature[[1]]$geometry$coordinates[2]
    return(c(lon,lat))
}



geocode <- function(address, citystatezip){
  # NOMINATIM SEARCH API URL
  src_url <- "https://nominatim.openstreetmap.org/search?q="
  
  # CREATE A FULL ADDRESS
  # put in + instead of space
  address = str_replace_all(string = address, pattern = "\\s", 
                         replacement = "+")
  citystatezip = gsub(" ","%2C",citystatezip)
  addr <- paste(address, citystatezip, sep = "%2C")
  
  # CREATE A SEARCH URL BASED ON NOMINATIM API TO RETURN GEOJSON
  requests <- paste0(src_url, addr, "&format=geojson")
  print(requests)
  
    
    # QUERY THE API TRANSFORM RESPONSE FROM JSON TO R LIST
    response <- read_html(requests) %>%
      html_node("p") %>%
      html_text() %>%
      fromJSON()
    
    
    # FROM THE RESPONSE EXTRACT LATITUDE AND LONGITUDE COORDINATES
    lon <- response$features[[1]]$geometry$coordinates[1]
    lat <- response$feature[[1]]$geometry$coordinates[2]
    return(c(lon,lat))
}
```
try it out
```{r}
a= geocode("5607 Baum Blvd","Pittsburgh, PA 15206")
a
```
```{r}
reverse_geocode_state <- function(lon,lat) {
  src_url <- "https://nominatim.openstreetmap.org/reverse?format=jsonv2&lat="
  lat = round(lat,digits=7)
  lon = round(lon,digits=7)
request=paste0(src_url,lat,"&lon=",lon)
  response <- read_html(request) %>% html_text() %>%
      fromJSON()
  return (response$address$state[1])
}
```
```{r}
print(round(a[2],digits=7))
s = reverse_geocode_state(a[1],a[2])
s
```
```{r}
lon = pa_geo$long[44]
lat = pa_geo$lat[44]
reverse_geocode_state(lon,lat)
```
# Get the exposure data

```{r}
frackdir='/Users/harry/OneDrive - University of Pittsburgh/Fracking Study Data'
setwd(frackdir)
edmr = "DEP eDMR Data"
edmr_dir = paste(frackdir,"/",edmr,sep="")
setwd(edmr_dir)
barium <- read.csv("./pa_dep_edmr_barium_bromide_chloride_strontium.csv")
bga<-read.csv("./pa_dep_edmr_total_beta_gross_alpha_2007-2020.csv")
radium<-read.csv("./pa_dep_edmr_total_radium226_radium228_2007-2020.csv")
uranium<-read.csv("./pa_dep_edmr_total_uranium_2007-2020.csv")
```
```{r}
blocs <- barium %>% select(Permit_Number,Latitude,Longitude)
blocs <- blocs[!duplicated(blocs), ]
bgalocs <- bga %>% select(Permit_Number,Latitude,Longitude)
bgalocs <-bgalocs[!duplicated(bgalocs),]
radlocs <- radium %>% select(Permit_Number,Latitude,Longitude)
radlocs <-radlocs[!duplicated(radlocs),]
uralocs <- uranium %>% select(Permit_Number,Latitude,Longitude)
uralocs <-uralocs[!duplicated(uralocs),]
```

graph it , using colors from http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/
```{r}
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
ggplot(data=pa_counties)+
  geom_sf()+
  geom_point(data=pa_geo,aes(x=long,y=lat),color=cbPalette[1],size=0.5)+
  geom_point(data=blocs,aes(x=Longitude,y=Latitude),color=cbPalette[2],size=0.5)+
  geom_point(data=bgalocs,aes(x=Longitude,y=Latitude),color=cbPalette[3],size=0.5)+
  geom_point(data=radlocs,aes(x=Longitude,y=Latitude),color=cbPalette[4],size=0.5)+
  geom_point(data=uralocs,aes(x=Longitude,y=Latitude),color=cbPalette[5],size=0.5)+
  theme_void()
```
just bga
```{r}
ggplot(data=pa_counties)+
  geom_sf()+
  geom_point(data=bgalocs,aes(x=Longitude,y=Latitude),color=cbPalette[3])+
  theme_void()
```
just radium
```{r}
ggplot(data=pa_counties)+
  geom_sf()+
  geom_point(data=radlocs,aes(x=Longitude,y=Latitude),color=cbPalette[4])+
  theme_void()
```
just uranium
```{r}
ggplot(data=pa_counties)+
  geom_sf()+
  geom_point(data=uralocs,aes(x=Longitude,y=Latitude),color=cbPalette[5])+
  theme_void()
```
```{r}
frackdir='/Users/harry/OneDrive - University of Pittsburgh/Fracking Study Data'
setwd(frackdir)
subdir = "DEP BCW Wastewater Facilities"
depdir = paste(frackdir,"/",subdir,sep="")
print(depdir)
setwd(depdir)
facilities<-read.csv("WMS_Permitted_Facilities_20210526.csv")
violations<-read.csv("WMS_Violations_ext.csv")
```
```{r}
facilities <- rename(facilities,CLNT_ID=CLIENT_ID)
```
```{r}
violation_facilities = merge(facilities,violations,by='CLNT_ID')
colnames(violation_facilities)
```
```{r}
nrow(violation_facilities)
```
get clint_id, location_address, and location address_city_state_zip
```{r}
violation_locs<- violation_facilities %>% select(CLNT_ID,LOCATION_ADDRESS,LOCATION_ADDRESS_CITY_STATE_ZIP)
violation_locs <-violation_locs[!duplicated(violation_locs),]
nrow(violation_locs)
``` 
```{r}
violation_locs$coords  = geocode(violation_locs$LOCATION_ADDRESS,violation_locs$LOCATION_ADDRESS_CITY_STATE_ZIP)
```
for i in range 1... # rows:
  print(i)
   get addresss , get city state zip
   get the geo code
   build up list of lat and long
   sleep(1)
   
```{r}
violation_locs[3,"LOCATION_ADDRESS"]
```

```{r}
loc = violation_locs[3,"LOCATION_ADDRESS"]
print(loc)
```
```{r}
city=violation_locs[3,"LOCATION_ADDRESS_CITY_STATE_ZIP"]
print(city)
```
```{r}
geocode(loc,city)
```
```{r}

geocode <- function(address, citystatezip){
  # NOMINATIM SEARCH API URL
  src_url <- "https://nominatim.openstreetmap.org/search?q="
  
  # CREATE A FULL ADDRESS
  # put in + instead of space
  address = str_replace_all(string = address, pattern = "\\s", 
                         replacement = "+")
  citystatezip = gsub(" ","%2C",citystatezip)
  addr <- paste(address, citystatezip, sep = "%2C")
  
  # CREATE A SEARCH URL BASED ON NOMINATIM API TO RETURN GEOJSON
  requests <- paste0(src_url, addr, "&format=geojson")
  print(requests)
  
    
    # QUERY THE API TRANSFORM RESPONSE FROM JSON TO R LIST
    response <- read_html(requests) %>%
      html_node("p") %>%
      html_text() %>%
      fromJSON()
    
    res=c("","")
    if (length(response$features) > 0) {
      # FROM THE RESPONSE EXTRACT LATITUDE AND LONGITUDE COORDINATES
      lon <- response$features[[1]]$geometry$coordinates[1]
      lat <- response$feature[[1]]$geometry$coordinates[2]
      res = paste(lon,",",lat)
    }
    return(res)
}
```
work this out by hand
```{r}
src_url <- "https://nominatim.openstreetmap.org/search?q="
loc = str_replace_all(string = loc, pattern = "\\s", 
                         replacement = "+")
city= gsub(" ","%2C",city)
addr <- paste(loc, city, sep = "%2C")
requests <- paste0(src_url, addr, "&format=geojson")
```
ok. make the request
```{r}
response <- read_html(requests) %>%
      html_node("p") %>%
      html_text() %>%
      fromJSON()
```
look at responses
```{r}
response
```
```{r}
length(response$features)==0
```
```{r}
lats<-vector()
longs<-vector()
for (i in 1:nrow(violation_locs)) {
  print(i)
  loc_address = violation_locs[i,"LOCATION_ADDRESS"]
  city_state = violation_locs[i,"LOCATION_ADDRESS_CITY_STATE_ZIP"]
  clint=violation_locs[i,"CLNT_ID"]
  latlong = geocode(loc_address,city_state)
  print(latlong)
  lon=latlong[1]
  lat=latlong[2]
  append(longs,lon)
  append(lats,lat)
  Sys.sleep(2)
}
violation_locs$lats=lats
violation_locs$longs=longs
```


